# USAGE# python detect.py --images images# import the necessary packagesfrom __future__ import print_functionfrom imutils.object_detection import non_max_suppressionfrom imutils import pathsimport numpy as npimport argparseimport imutilsimport cv2import xml.etree.ElementTree as ET# 定义旋转rotate函数def rotate(image, angle, center=None, scale=1.0):    # 获取图像尺寸    (h, w) = image.shape[:2]    # 若未指定旋转中心，则将图像中心设为旋转中心    if center is None:        center = (w / 2, h / 2)    # 执行旋转    M = cv2.getRotationMatrix2D(center, angle, scale)    rotated = cv2.warpAffine(image, M, (w, h))    # 返回旋转后的图像    return rotated# initialize the HOG descriptor/person detectorhog = cv2.HOGDescriptor()# hog.load('./detector/cascade.xml')svm = cv2.HOGDescriptor_getDefaultPeopleDetector()# svm.load('./detector/cascade.xml')# svm =# hog.setSVMDetector(svm)# svm = cv2.ml.SVM_load('./detector/cascade.xml')hog.setSVMDetector(svm)camera = cv2.VideoCapture('./videos/test01.mp4')# 初始化视频流的第一帧firstFrame = Nonewhile True:  # 获取当前帧并初始化occupied/unoccupied文本  (grabbed, frame) = camera.read()  text = "Unoccupied"  # 如果不能抓取到一帧，说明我们到了视频的结尾  if not grabbed:    break  # 调整该帧的大小，转换为灰阶图像并且对其进行高斯模糊  frame = imutils.resize(frame, width=500)  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  gray = cv2.GaussianBlur(gray, (21, 21), 0)  # 如果第一帧是None，对其进行初始化  if firstFrame is None:    firstFrame = gray    continue  newframe = rotate(frame, 270)  nmsFrame = newframe.copy()  # cv2.imshow('gray',gray)  # 背景去除, 差值大于50的像素留下  frameDelta = cv2.absdiff(firstFrame, gray)  thresh = cv2.threshold(frameDelta, 25, 255, cv2.THRESH_BINARY)[1]  result = np.hstack((gray, thresh))  # cv2.imshow('result', result)  # detect people in the image  rects, weights = hog.detectMultiScale(newframe, winStride=(4, 4), padding=(8, 8), scale=1.05)  # rects, weights = hog.detectMultiScale(newframe)  # draw the original bounding boxes  for (x, y, w, h) in rects:      cv2.rectangle(newframe, (x, y), (x + w, y + h), (0, 0, 255), 2)  # apply non-maxima suppression to the bounding boxes using a  # fairly large overlap threshold to try to maintain overlapping  # boxes that are still people  rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])  pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)  # draw the final bounding boxes  for (xA, yA, xB, yB) in pick:      cv2.rectangle(nmsFrame, (xA, yA), (xB, yB), (0, 255, 0), 2)  # cv2.imshow("Before NMS", newframe)  # cv2.imshow("After NMS", nmsFrame)  result = np.hstack((newframe, nmsFrame))  cv2.imshow("Detecting", result)  cv2.waitKey(0)