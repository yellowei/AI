# import the necessary packagesfrom __future__ import print_functionfrom imutils.object_detection import non_max_suppressionfrom imutils import pathsimport os.pathimport shutilimport numpy as npimport argparse #argparse是一个全面的参数处理库import imutilsimport cv2# 定义旋转rotate函数def rotate(image, angle, center=None, scale=1.0):    # 获取图像尺寸	(h, w) = image.shape[:2]    # 若未指定旋转中心，则将图像中心设为旋转中心    if center is None:        center = (w / 2, h / 2)    # 执行旋转    M = cv2.getRotationMatrix2D(center, angle, scale)    rotated = cv2.warpAffine(image, M, (w, h))    # 返回旋转后的图像    return rotated# construct the argument parse and parse the argumentsap = argparse.ArgumentParser() #解析器类是 ArgumentParser 。构造方法接收几个参数来设置用于程序帮助文本的描述信息以及其他全局的行为或设置ap.add_argument("-i", "--images", help="path to images directory")ap.add_argument("-v", "--videos", help="path to videos directory")args = vars(ap.parse_args())   #等待用户输入参数,用args来接收这个参数# initialize the HOG descriptor/person detectorhog = cv2.HOGDescriptor()hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())# default the value of images pathimagePaths = list(paths.list_images("./images"))# loop over the image paths 遍历图像文件if args["images"]:	imagePaths = list(paths.list_images(args["images"])) #导入输入目录的图片列表#loop over the video pathsif args["videos"]:	if os.path.exists("./videoToimages/"):		shutil.rmtree("./videoToimages/")	# create the image folder path	if not os.path.exists("./videoToimages/"):		os.mkdir("./videoToimages/")	videoPaths = list(os.listdir(args["videos"])) #导入输入目录的视频列表	for videoPath in videoPaths:		vc = cv2.VideoCapture(args["videos"]+'/'+videoPath)  # 读入视频文件		c = 0		rval = vc.isOpened()		#timeF = 1  #视频帧计数间隔频率		while rval:  # 循环读取视频帧			c = c + 1			rval, frame = vc.read()			# if(c%timeF == 0): #每隔timeF帧进行存储操作			# 	cv2.imwrite('images/'+str(c) + '.jpg', frame) #存储为图像			# else:			# 	break			rotated = rotate(frame, 270)			if rval:				cv2.imwrite('videoToimages/' + str(c).zfill(8) + '.jpg', rotated)  # 存储为图像				cv2.waitKey(0)			else:				break		vc.release()	imagePaths = list(paths.list_images("./videoToimages"))for imagePath in imagePaths:	# load the image and resize it to (1) reduce detection time	# and (2) improve detection accuracy	image = cv2.imread(imagePath)	image = imutils.resize(image, width=min(400, image.shape[1]))	orig = image.copy()	# detect people in the image	(rects, weights) = hog.detectMultiScale(image, winStride=(4, 4),		padding=(8, 8), scale=1.05)	# draw the original bounding boxes	for (x, y, w, h) in rects:		cv2.rectangle(orig, (x, y), (x + w, y + h), (0, 0, 255), 2)	# apply non-maxima suppression to the bounding boxes using a	# fairly large overlap threshold to try to maintain overlapping	# boxes that are still people	rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])	pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)	# draw the final bounding boxes	for (xA, yA, xB, yB) in pick:		cv2.rectangle(image, (xA, yA), (xB, yB), (0, 255, 0), 2)	# show some information on the number of bounding boxes	filename = imagePath[imagePath.rfind("/") + 1:]	print("[INFO] {}: {} original boxes, {} after suppression".format(filename, len(rects), len(pick)))	# show the output images	cv2.imshow("Before NMS", orig)	cv2.imshow("After NMS", image)	cv2.waitKey(0)